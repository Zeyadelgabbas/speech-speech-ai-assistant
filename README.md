# ğŸ¤ Speech-to-Speech AI Voice Assistant

> **An intelligent, privacy-focused voice assistant with conversational memory, tool execution, and real-time speech interaction**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-success)](https://github.com/Zeyadelgabbas/speech-speech-ai-assistant)

---

## ğŸŒŸ Overview

A production-ready voice assistant that combines **Speech-to-Text (STT)**, **Large Language Models (LLMs)**, and **Text-to-Speech (TTS)** into a seamless conversational experience. Built with local processing capabilities and intelligent function calling, it offers session-based memory, document search (RAG), web search, Gmail integration, and real-time voice activity detection.

**Perfect for:** Portfolio projects, AI engineering demonstrations, and understanding end-to-end voice AI systems.

---

## âœ¨ Key Features

### ğŸ™ï¸ **Dual Recording Modes**
- **Press-to-Speak**: Fixed 5-second recording for precise control
- **Voice Activity Detection (VAD)**: Hands-free operation with automatic speech detection using **WebRTC VAD**

### ğŸ§  **Intelligent Conversation**
- **LLM-Powered**: Uses OpenAI GPT-4 with function calling for natural responses
- **Session Memory**: Persistent conversation history with SQLite storage
- **User Profiling**: Long-term preference learning and personalization

### ğŸ”§ **5 Production Tools**
| Tool | Description | Integration |
|------|-------------|-------------|
| ğŸŒ **Web Search** | Real-time Google search | SerpAPI |
| ğŸ“š **RAG Query** | Document Q&A system | ChromaDB + OpenAI Embeddings |
| âœ‰ï¸ **Gmail Drafts** | Email composition (no auto-send) | Google Gmail API (OAuth2) |
| ğŸ“ **Notes Manager** | Quick note storage/retrieval | Local file system |
| ğŸ’¾ **File Writer** | Export conversations/summaries | Text file export |

### ğŸ“Š **Analytics & Monitoring**
- Real-time cost tracking (tokens, API calls)
- Usage statistics dashboard
- Tool execution frequency
- Session duration & error rates

---

## ğŸ¬ User Experience

### **Startup**
```
ğŸ¤ VOICE AI ASSISTANT v1.0

ğŸ“š Saved Sessions:
   [1] meeting notes (10 messages, 2025-11-12)
   [2] project planning (15 messages, 2025-11-11)

Options:
  â€¢ Type 1-2 to load session
  â€¢ Press ENTER for new session
  â€¢ Type 'stats' for analytics

Choice: _
```

### **Conversation Flow**
```
ğŸ§‘ User: What's the weather in Cairo today?

ğŸ¤– Thinking...
   ğŸ”§ [web_search]...

ğŸ¤– Assistant: The weather in Cairo is sunny with 28Â°C...
ğŸ”Š Speaking...

âºï¸  Ready to listen...
```

### **Voice Commands**
- `"save session"` â†’ Save with custom name
- `"load session"` â†’ Resume previous conversation
- `"draft email to john@example.com"` â†’ Create Gmail draft
- `"search my documents for budget"` â†’ Query RAG database
- `"speak slower"` â†’ Adjust TTS speed

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Voice Assistant                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Audio Input â†’ STT â†’ LLM + Tools â†’ TTS â†’ Audio Out â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Pipeline:
1. Record Audio (Press-to-Speak or VAD)
2. Transcribe (Faster Whisper)
3. Route Commands / Call LLM (GPT-4 + Function Calling)
4. Execute Tools (Web/RAG/Gmail/Notes/Files)
5. Synthesize Speech (Piper TTS)
6. Play Audio (Speakers)
7. Log Analytics
```

### **Tech Stack**

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **STT** | Faster Whisper (`base` model) | High-accuracy speech recognition (16kHz) |
| **LLM** | OpenAI GPT-4 Turbo | Natural language understanding + tool orchestration |
| **TTS** | Piper TTS (ONNX) | Natural speech synthesis (22kHz) |
| **VAD** | WebRTC VAD (Level 3) | Real-time silence detection |
| **Vector DB** | ChromaDB | Document embeddings for RAG |
| **Embeddings** | OpenAI `text-embedding-3-small` | 1536-dim semantic search |
| **Web Search** | SerpAPI | Real-time Google search results |
| **Email** | Google Gmail API (OAuth2) | Draft creation (no auto-send) |
| **Memory** | SQLite + JSON | Session persistence + analytics |
| **Tools** | LangChain-style function calling | Dynamic tool selection |

---

## ğŸš€ Quick Start

### **Prerequisites**
- Python 3.10+
- Microphone + Speakers
- OpenAI API key
- SerpAPI key (optional: 100 free searches/month)

### **Installation**
```bash
# Clone repository
git clone https://github.com/Zeyadelgabbas/speech-speech-ai-assistant.git
cd speech-speech-ai-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env with your keys
```

### **Run**
```bash
# Test setup
python tests/test_integration.py

# Launch assistant
python main.py
```

---

## ğŸ“‹ Configuration

Edit `.env`:
```bash
# Required
OPENAI_API_KEY=sk-proj-your_key_here
SERP_API_KEY=your_serpapi_key_here

# Optional
WHISPER_MODEL_SIZE=base  # tiny/small/medium/large
PIPER_VOICE=en_US-lessac-medium
VAD_AGGRESSIVENESS=3  # 0-3 (3=most sensitive)
```

---

## ğŸ”§ Features Breakdown

### **1. Retrieval-Augmented Generation (RAG)**
- Upload PDFs/text files: `python src/scripts/ingest_documents.py --file doc.pdf`
- Query with voice: `"What does my document say about budget?"`
- Semantic search with ChromaDB + OpenAI embeddings

### **2. Gmail Integration**
- OAuth2 setup: `python src/scripts/setup_google_oauth.py`
- Voice command: `"Draft email to boss about project update"`
- Creates draft in Gmail (user reviews before sending)

### **3. Session Management**
- Auto-save conversations with custom names
- Load previous sessions with full context
- SQLite persistence with conversation history

### **4. Smart Tool Selection**
- Context-aware tool activation (reduces token usage)
- Always available: Notes, File Writer
- Conditional: Web Search, RAG, Gmail (triggered by keywords)

---

## ğŸ“Š Analytics Dashboard

View comprehensive statistics:
```bash
Choice: stats
```

**Metrics tracked:**
- Total sessions, messages, tokens (prompt + completion)
- Estimated API costs
- Tool execution frequency
- Average session duration & messages per session
- Error rates and performance metrics

---

## ğŸ¯ Use Cases

- **Personal Assistant**: Schedule management, note-taking, reminders
- **Document Q&A**: Query your PDFs and documents with natural language
- **Email Drafting**: Compose emails hands-free with Gmail integration
- **Research Tool**: Web search integration for real-time information
- **Learning & Development**: Portfolio project demonstrating AI engineering skills

---

## ğŸ› ï¸ Development

### **Project Structure**
```
speech-speech-ai-assistant/
â”œâ”€â”€ main.py                      # Entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ assistant/              # Core orchestration
â”‚   â”œâ”€â”€ audio/                  # Recording, playback, VAD
â”‚   â”œâ”€â”€ stt/                    # Faster Whisper integration
â”‚   â”œâ”€â”€ tts/                    # Piper TTS
â”‚   â”œâ”€â”€ llm/                    # OpenAI client + prompts
â”‚   â”œâ”€â”€ memory/                 # Session, user, vector DB
â”‚   â”œâ”€â”€ tools/                  # Function calling tools
â”‚   â””â”€â”€ utils/                  # Config, logging
â”œâ”€â”€ data/                       # User data (gitignored)
â””â”€â”€ tests/                      # Integration tests
```

### **Adding New Tools**
1. Create tool class inheriting from `BaseTool`
2. Implement `name`, `description`, `parameters_schema`, `execute()`
3. Register in `VoiceAssistant._register_tools()`

---

## ğŸ› Troubleshooting

**Microphone Issues:**
```bash
python -m sounddevice  # List audio devices
```

**API Errors:**
- Verify API keys in `.env`
- Check OpenAI account credits

**VAD Not Detecting Speech:**
- Adjust `VAD_AGGRESSIVENESS` (0-3)
- Use Press-to-Speak mode instead

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) file

---

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or submit a pull request.

---

## ğŸ‘¤ Author

**Zeyad Emad**
- GitHub: [@Zeyadelgabbas](https://github.com/Zeyadelgabbas)
- LinkedIn: [Zeyad Elgabas](https://www.linkedin.com/in/zeyad-elgabas-9862082b7)
- Email: Zeyadelgabas@gmail.com

---

## ğŸŒŸ Acknowledgments

Built with:
- [Faster Whisper](https://github.com/guillaumekln/faster-whisper)
- [Piper TTS](https://github.com/rhasspy/piper)
- [OpenAI API](https://platform.openai.com/) 
- [ChromaDB](https://www.trychroma.com/)
- [LangChain](https://www.langchain.com/)

---

**â­ If you find this project useful, please star the repository!**